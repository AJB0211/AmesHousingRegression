{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from plotnine import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import norm    # used in plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"./data/train.csv\")\n",
    "testData = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = ((trainData.GrLivArea > 4000) & (trainData.SalePrice < 5E5))\n",
    "trainData = trainData[~(outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning = trainData.groupby(\"Neighborhood\").MSZoning.apply(lambda x: x.value_counts().sort_values().index[0]).to_dict()\n",
    "utilities = trainData.groupby(\"Neighborhood\").Utilities.apply(lambda x: x.value_counts().sort_values().index[0]).to_dict()\n",
    "frontage = trainData.groupby(\"Neighborhood\").LotFrontage.apply(lambda x: x.value_counts().sort_values().index[0]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't know what to do with these yet\n",
    "# Maybe harmonic transform on month. \n",
    "# Maybe diff between year sold and built\n",
    "timeVars = [\"MoSold\",\"YrSold\",\"YearBuilt\"]\n",
    "\n",
    "# CentralAir needs to be examined for correlation\n",
    "toInclude = [\"LotFrontage\",\"CentralAir\",\"Electrical\",\"Functional\",\"MSZoning\",\"Utilities\",\n",
    "            \"KitchenQual\",\"SaleType\",\"Exterior1st\",\"Exterior2nd\",\"CentralAir\"]\n",
    "\n",
    "examine =  [\"MSSubClass\", \"LotArea\",\"Street\",\"Alley\",\"LotShape\",\"LandContour\",\n",
    "          \"LotConfig\",\"LandSlope\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"BldgType\",\"HouseStyle\",\n",
    "          \"OverallQual\",\"OverallCond\",\"RoofStyle\",\"RoofMatl\",\"ExterQual\",\n",
    "          \"ExterCond\",\"Foundation\",\"Heating\",\"HeatingQC\",\"TotsRmsAbvGr\",\"PavedDrive\",\"EnclosedPorch\",\n",
    "          \"3SsnPorch\",\"ScreenPorch\",\"MiscVal\",\"SaleCondition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These variables differ for nonlinear models (linearly dependent features)\n",
    "# values that null is filled with \"None\"\n",
    "fillNone = [\"Alley\",\"BsmtQual\",\"BsmtCond\",\"MasVnrType\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\n",
    "            \"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\n",
    "            \"PoolQC\",\"Fence\",\"MiscFeature\",\"MasVnrType\"]\n",
    "\n",
    "# ordinal categorical variables\n",
    "fillZeroCat = [\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"GarageCars\"]\n",
    "\n",
    "# continuous variables with missing values that are zero\n",
    "fillZeroCont = [\"MasVnrArea\",\"GarageArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\n",
    "                \"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\", \"TotalBsmtSF\"]\n",
    "\n",
    "# variables that need differences between reference engineered\n",
    "imputeDiff = [(\"GarageYrBlt\",\"YearBuilt\"),(\"YearRemodAdd\",\"YearBuilt\")]\n",
    "\n",
    "# categories that we need to know if they were imputed\n",
    "imputeUnknown = []\n",
    "\n",
    "# to be dropped\n",
    "dropList = [\"Id\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are for the linear model\n",
    "selected=[]\n",
    "# values that null is filled with \"None\"\n",
    "fillNone = [\"Alley\",\"BsmtQual\",\"BsmtCond\",\"MasVnrType\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\n",
    "            \"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\n",
    "            \"PoolQC\",\"Fence\",\"MiscFeature\",\"MasVnrType\",\"MSZoning\",\"Utilities\"]\n",
    "\n",
    "# ordinal categorical variables\n",
    "fillZeroCat = [\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"GarageCars\",\"Fireplaces\"]\n",
    "\n",
    "# continuous variables with missing values that are zero\n",
    "fillZeroCont = [\"MasVnrArea\",\"GarageArea\",\"GrLivArea\",\"1stFlrSF\",\"2ndFlrSF\",\"LotFrontage\",I used all the categorical variables\n",
    "                \"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"WoodDeckSF\",\"OpenPorchSF\",\"PoolArea\"]\n",
    "\n",
    "# variables that need differences between reference engineered\n",
    "imputeDiff = [(\"GarageYrBlt\",\"YearBuilt\"),(\"YearRemodAdd\",\"YearBuilt\")]\n",
    "\n",
    "# categories that we need to know if they were imputed\n",
    "imputeUnknown = []\n",
    "\n",
    "# to be dropped\n",
    "dropList = [\"TotalBsmtSF\",\"Id\",\"GarageYrBlt\",\"YearRemodAdd\"]\n",
    "\n",
    "imputeDict = {\"Electrical\": \"SBrkr\", \n",
    "              \"Functional\": \"Typ\", \n",
    "              \"CentralAir\":\"Y\",\n",
    "              \"KitchenQual\":\"Po\",\n",
    "              \"SaleType\":\"Oth\",\n",
    "              \"Exterior1st\":\"Other\",\n",
    "              \"Exterior2nd\":\"Other\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"garageDiff\"] = trainData.GarageYrBlt-trainData.YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"remodDiff\"] = trainData.YearRemodAdd - trainData.YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeVals2(in_df):\n",
    "    df = in_df.copy()\n",
    "    df.LotFrontage = df.LotFrontage.fillna(df.Neighborhood.map(frontage))  \n",
    "    df.MSZoning = df.MSZoning.fillna(df.Neighborhood.map(zoning))\n",
    "    df.Utilities = df.Utilities.fillna(df.Neighborhood.map(utilities))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = trainData.drop(columns=[\"SalePrice\"])\n",
    "train_y = trainData.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_X = imputeVals2(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class dictImputer(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,dict_: dict):\n",
    "        self.dict_ = dict_\n",
    "         \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        for k,v in self.dict_.items():\n",
    "            X[k] = X[k].fillna(v)\n",
    "        return X[self.dict_.keys()]  \n",
    "    \n",
    "## Example:\n",
    "# dictImputer(imputeDict).fit_transform(pipe_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-2e5c5d376d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnonePipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mzeroPipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscalePipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m regressionPipeline = ColumnTransformer([\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'drop'"
     ]
    }
   ],
   "source": [
    "nonePipeline = make_pipeline(SimpleImputer(strategy=\"constant\",fill_value=\"None\"),OneHotEncoder(drop=\"first\",handle_unknown=\"ignore\"))\n",
    "zeroPipeline = make_pipeline(SimpleImputer(strategy=\"constant\",fill_value=0),OneHotEncoder(drop=\"first\",handle_unknown=\"ignore\"))\n",
    "scalePipeline = make_pipeline(SimpleImputer(strategy=\"constant\",fill_value=0),StandardScaler())\n",
    "\n",
    "regressionPipeline = ColumnTransformer([\n",
    "    (\"setNone\", nonePipeline,fillNone),\n",
    "    (\"setZero\", zeroPipeline,fillZeroCat),\n",
    "    (\"transformed\", scalePipeline, fillZeroCont),\n",
    "    (\"dictImputed\", make_pipeline(dictImputer(imputeDict),OneHotEncoder(drop=\"first\",handle_unknown=\"ignore\")),list(imputeDict.keys())),\n",
    "    #(\"selected\", \"passthrough\", selected),\n",
    "    (\"dropped\", \"drop\", dropList)\n",
    "],remainder=\"drop\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "piped_X = regressionPipeline.fit_transform(pipe_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetScaler =  StandardScaler()\n",
    "pipe_y = targetScaler.fit_transform(np.log(train_y.values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ElasticNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm_params = {\"alpha\": np.logspace(-5,2,50), \"l1_ratio\": np.linspace(0,1,50)}\n",
    "\n",
    "lm_grid = GridSearchCV(lm, lm_params, cv = 5, scoring = \"neg_mean_squared_error\", n_jobs = -1, verbose=50)\n",
    "lm_grid.fit(piped_X,pipe_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869333586280218"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_params = {'alpha': 0.013894954943731374, 'l1_ratio': 0.02040816326530612}\n",
    "\n",
    "test_net = ElasticNet(**lm_params)\n",
    "\n",
    "test_net.fit(piped_X,pipe_y)\n",
    "test_net.score(piped_X,pipe_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "piped_test_X = regressionPipeline.transform(imputeVals2(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = test_net.predict(piped_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outvals = np.exp(targetScaler.inverse_transform(raw_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_frame = pd.DataFrame()\n",
    "submit_frame['Id'] = testData.Id\n",
    "submit_frame['SalePrice'] = outvals\n",
    "submit_frame.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'alpha': 0.013894954943731374, 'l1_ratio': 0.02040816326530612}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
